{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Scoping du projet"
      ],
      "metadata": {
        "id": "ml808zYlkaeX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Le jeu de données que vous nous avons la charge de travailler contient des informations sous forme de paires de phrases (prémisse et hypothèse) avec des métadonnées telles que les identifiants, les abréviations de langue et les étiquettes de langue. Ce jeu de données semble être utilisé pour des tâches de compréhension de langage naturel, comme la classification d'inférence ou la prédiction de la relation entre la prémisse et l'hypothèse. En ce qui nous concerne, nous sommes charger de classifier la colonne \"promised\" + \"hypothesis\" en fonction du label correspondant.\n",
        "\n",
        "1. **Objectif du projet** :\n",
        "   - L'objectif principal est de développer un modèle de Deep Learning capable de prédire la relation entre la prémisse et l'hypothèse dans chaque paire de phrases.\n",
        "\n",
        "2. **Tâche** :\n",
        "   - Tâche de classification : Prédire la relation entre la prémisse et l'hypothèse. Les classes peuvent être les différentes relations possibles telles que \"Contradiction\", \"Entailment\" et \"Neutral\".\n",
        "\n",
        "3. **Métriques d'évaluation** :\n",
        "   - Les métriques d'évaluation appropriées pour cette tâche pourraient inclure la précision, le rappel, la F1-score, et la matrice de confusion.\n",
        "\n",
        "4. **Collecte et préparation des données** :\n",
        "   - Prétraitement : Nettoyer le texte en retirant les caractères spéciaux, en normalisant la casse, etc.\n",
        "   - Diviser le jeu de données en ensembles d'entraînement, de validation et de test.\n",
        "\n",
        "5. **Architecture du modèle** :\n",
        "   - Choisissez une architecture appropriée pour la tâche, telle qu'un modèle basé sur Transformer (BERT, RoBERTa, etc.) ou des réseaux de neurones récurrents (LSTM, GRU) en fonction de la complexité de la tâche.\n",
        "\n",
        "6. **Entraînement et évaluation du modèle** :\n",
        "   - Entraînez le modèle sur l'ensemble d'entraînement et ajustez les hyperparamètres pour optimiser les performances.\n",
        "   - Évaluez le modèle sur l'ensemble de validation pour surveiller le surapprentissage et ajuster les paramètres en conséquence.\n",
        "\n",
        "7. **Tests finaux** :\n",
        "   - Évaluez le modèle final sur l'ensemble de test pour obtenir une évaluation impartiale de ses performances.\n",
        "\n",
        "8. **Communication des résultats** :\n",
        "   - Présentez les performances du modèle à l'aide de métriques appropriées dans un rapport ou une présentation.\n",
        "\n",
        "9. **Itérations** :\n",
        "   - En fonction des performances du modèle, effectuez des itérations pour ajuster les hyperparamètres, essayer différentes architectures et améliorer les résultats.\n",
        "\n",
        "10. **Gestion des ressources** :\n",
        "   - Assurez-vous d'avoir suffisamment de puissance de calcul pour l'entraînement des modèles et de prévoir des ressources pour les expériences itératives.\n",
        "\n",
        "11. **Limitations et risques** :\n",
        "   - Identifiez les limitations potentielles du modèle, telles que la nécessité d'un grand volume de données annotées et les défis liés aux langues moins courantes."
      ],
      "metadata": {
        "id": "LOwpBge1sYdp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data"
      ],
      "metadata": {
        "id": "NWLouatrtmui"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#!pip install xlrd\n",
        "\n"
      ],
      "metadata": {
        "id": "z_fnmbWYEGYm"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd"
      ],
      "metadata": {
        "id": "ThlB-AjfBksy"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yZ2thxyLAJqj",
        "outputId": "8b211769-dff8-4ea1-bb41-56cc9970e0cd"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Charger le jeu de données\n",
        "df = pd.read_excel('/content/drive/Othercomputers/Mon ordinateur/DIT MASTER1 2022/MASTER 2/DEEP LEARNING/devoir/contradictory-my-dear.xlsx')"
      ],
      "metadata": {
        "id": "Uzm7hLI1ASKO"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "eZv2yqWEEWgh",
        "outputId": "9a238197-7aab-44e3-e00c-4c5ab2d504d8"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "           id                                            premise  \\\n",
              "0  5130fd2cb5  and these comments were considered in formulat...   \n",
              "1  5b72532a0b  These are issues that we wrestle with in pract...   \n",
              "2  3931fbe82a  Des petites choses comme celles-là font une di...   \n",
              "3  5622f0c60b  you know they can't really defend themselves l...   \n",
              "4  86aaa48b45  ในการเล่นบทบาทสมมุติก็เช่นกัน โอกาสที่จะได้แสด...   \n",
              "\n",
              "                                          hypothesis lang_abv language  label  \n",
              "0  The rules developed in the interim were put to...       en  English      0  \n",
              "1  Practice groups are not permitted to work on t...       en  English      2  \n",
              "2              J'essayais d'accomplir quelque chose.       fr   French      0  \n",
              "3  They can't defend themselves because of their ...       en  English      0  \n",
              "4    เด็กสามารถเห็นได้ว่าชาติพันธุ์แตกต่างกันอย่างไร       th     Thai      1  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-ce04b0dd-762d-4a58-a579-07f8bcfc5c91\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>premise</th>\n",
              "      <th>hypothesis</th>\n",
              "      <th>lang_abv</th>\n",
              "      <th>language</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>5130fd2cb5</td>\n",
              "      <td>and these comments were considered in formulat...</td>\n",
              "      <td>The rules developed in the interim were put to...</td>\n",
              "      <td>en</td>\n",
              "      <td>English</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>5b72532a0b</td>\n",
              "      <td>These are issues that we wrestle with in pract...</td>\n",
              "      <td>Practice groups are not permitted to work on t...</td>\n",
              "      <td>en</td>\n",
              "      <td>English</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3931fbe82a</td>\n",
              "      <td>Des petites choses comme celles-là font une di...</td>\n",
              "      <td>J'essayais d'accomplir quelque chose.</td>\n",
              "      <td>fr</td>\n",
              "      <td>French</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>5622f0c60b</td>\n",
              "      <td>you know they can't really defend themselves l...</td>\n",
              "      <td>They can't defend themselves because of their ...</td>\n",
              "      <td>en</td>\n",
              "      <td>English</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>86aaa48b45</td>\n",
              "      <td>ในการเล่นบทบาทสมมุติก็เช่นกัน โอกาสที่จะได้แสด...</td>\n",
              "      <td>เด็กสามารถเห็นได้ว่าชาติพันธุ์แตกต่างกันอย่างไร</td>\n",
              "      <td>th</td>\n",
              "      <td>Thai</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ce04b0dd-762d-4a58-a579-07f8bcfc5c91')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-ce04b0dd-762d-4a58-a579-07f8bcfc5c91 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-ce04b0dd-762d-4a58-a579-07f8bcfc5c91');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-6f9196d1-de1e-4fc8-bbcc-f602a7c3c8ad\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-6f9196d1-de1e-4fc8-bbcc-f602a7c3c8ad')\"\n",
              "            title=\"Suggest charts.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-6f9196d1-de1e-4fc8-bbcc-f602a7c3c8ad button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WYRkg3OjJOZF",
        "outputId": "8e02fdc2-b370-45d7-ad07-82632ea6400d"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "12120"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Compter le nombre de labels distincts\n",
        "num_unique_labels = df['label'].nunique()\n",
        "print(num_unique_labels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N-hTbvK0Ji4D",
        "outputId": "124231cb-5027-446e-899f-522f69d83045"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Afficher les labels distincts\n",
        "unique_labels = df['label'].unique()\n",
        "print(f\"Labels distincts : {unique_labels}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dHDcMgH4J4I9",
        "outputId": "4557b224-1d98-4738-8f99-2fbdc5ff11c5"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Labels distincts : [0 2 1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Compter le nombre de langues distinctes\n",
        "num_unique_language = df['language'].nunique()\n",
        "print(f\"Nombre de langues distinctes : {num_unique_language}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xKV5n4BZKXf2",
        "outputId": "5f1b937f-3413-428d-c0ec-5cbe78f01d0e"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Nombre de langues distinctes : 15\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Afficher les langues distincts\n",
        "unique_language = df['language'].unique()\n",
        "print(f\"langues distinctes : {unique_language}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pXiT7znbKdZG",
        "outputId": "a6665f69-f307-4ac8-8899-9ab157b2a780"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "langues distinctes : ['English' 'French' 'Thai' 'Turkish' 'Urdu' 'Russian' 'Bulgarian' 'German'\n",
            " 'Arabic' 'Chinese' 'Hindi' 'Swahili' 'Vietnamese' 'Spanish' 'Greek']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Modeling"
      ],
      "metadata": {
        "id": "Op--OBHCs-9g"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "ZO0bcql4xR8h"
      },
      "outputs": [],
      "source": [
        "#!pip install transformers\n",
        "#!pip install wandb"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer, BertModel, AdamW, PreTrainedModel, BertPreTrainedModel\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch.optim as optim\n",
        "import pandas as pd\n",
        "import torch.nn.functional as F\n",
        "from huggingface_hub import PyTorchModelHubMixin\n",
        "\n",
        "\n",
        "from tqdm import tqdm\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import wandb"
      ],
      "metadata": {
        "id": "2SEf4Ou4dflF"
      },
      "execution_count": 115,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "config = {\n",
        "    \"num_epochs\" : 1,\n",
        "    \"max_length\" : 80,\n",
        "    \"num_classes\" : 3,\n",
        "    \"learning_rate\" : 2e-5,\n",
        "    \"batch_size\" : 16,\n",
        "    \"shuffle\" : True,\n",
        "    \"model_name\" : 'bert-base-multilingual-cased',\n",
        "    \"device\" : torch.device('cuda' if torch.cuda.is_available() else 'cpu'),\n",
        "    \"file\" : \"/content/drive/Othercomputers/Mon ordinateur/DIT MASTER1 2022/MASTER 2/DEEP LEARNING/devoir/contradictory-my-dear.xlsx\"\n",
        "}"
      ],
      "metadata": {
        "id": "VZ3gIPPgdoBl"
      },
      "execution_count": 92,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MyDataset(Dataset):\n",
        "    def __init__(self, excel_file, tokenizer, max_length):\n",
        "        self.df = pd.read_excel(excel_file)\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_length = max_length\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "\n",
        "        item = self.df.iloc[index]\n",
        "        premise = item['premise']\n",
        "        hypothesis = item['hypothesis']\n",
        "        label = item['label']\n",
        "\n",
        "        inputs = self.tokenizer(premise, hypothesis, max_length=self.max_length, padding='max_length', truncation=True, return_tensors='pt')\n",
        "\n",
        "        return {\n",
        "            \"input_ids\" : inputs['input_ids'],\n",
        "            \"attention_mask\" : inputs['attention_mask'],\n",
        "            \"label\" : torch.tensor(label)\n",
        "        }"
      ],
      "metadata": {
        "id": "-68oRoPgdrJ2"
      },
      "execution_count": 93,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# dataloader\n",
        "def dataloader(dataset, batch_size, shuffle):\n",
        "    return DataLoader(dataset=dataset, batch_size= batch_size, shuffle=shuffle)"
      ],
      "metadata": {
        "id": "W3mtCyUpdurK"
      },
      "execution_count": 94,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomModel(nn.Module, PyTorchModelHubMixin):\n",
        "    def __init__(self, model_name, num_classes):\n",
        "        super(CustomModel, self).__init__()\n",
        "        self.pretrained_model = BertModel.from_pretrained(model_name) # 768 corresponds to the BERT's output size\n",
        "        self.classifier = nn.Linear(768, num_classes)   # MLP\n",
        "\n",
        "    def forward(self, input_ids, attention_mask):\n",
        "        output = self.pretrained_model(input_ids=input_ids, attention_mask=attention_mask) # (bacth 768)\n",
        "        output = self.classifier(output.last_hidden_state)\n",
        "        return output"
      ],
      "metadata": {
        "id": "BxLiDo-MdxVi"
      },
      "execution_count": 118,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# training step\n",
        "def train_step(model, train_loader, optimizer, loss_fn, device):\n",
        "    model.train()\n",
        "\n",
        "    total_loss = 0\n",
        "\n",
        "    for data in tqdm(train_loader, total = len(train_loader)):\n",
        "        inputs = data['input_ids'].to(device)\n",
        "        attention_mask = data['attention_mask'].to(device)\n",
        "        targets = data['label'].to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        output = model(inputs.squeeze(1), attention_mask)\n",
        "        loss = loss_fn(output, F.one_hot(targets, num_classes=3))\n",
        "\n",
        "        # backward\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    return  total_loss / len(train_loader)"
      ],
      "metadata": {
        "id": "nb0B5WIId1at"
      },
      "execution_count": 96,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def validation_step(model, validation_loader, loss_fn, device):\n",
        "    total_loss = 0\n",
        "    correct_prediction = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for data in tqdm(validation_loader, total = len(validation_loader)):\n",
        "            input_ids = data['input_ids'].squeeze(1).to(device)\n",
        "            attention_mask = data['attention_mask'].to(device)\n",
        "            targets = data['label'].to(device)\n",
        "\n",
        "            output = model(input_ids = input_ids, attention_mask = attention_mask)\n",
        "            loss = loss_fn(output, F.one_hot(targets, num_classes=3))\n",
        "\n",
        "            total_loss += loss.item()\n",
        "\n",
        "            pred = torch.max(torch.softmax(output, dim=1), dim = 1)\n",
        "            correct_prediction += torch.sum(pred.indices==F.one_hot(targets, num_classes=3))\n",
        "\n",
        "\n",
        "        return  total_loss / len(validation_loader), 100*correct_prediction/len(validation_loader)"
      ],
      "metadata": {
        "id": "M5GXVrIpd6Y6"
      },
      "execution_count": 97,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# main\n",
        "def main():\n",
        "    wandb.init('bert_classification')\n",
        "\n",
        "    tokenizer = AutoTokenizer.from_pretrained(config['model_name'])\n",
        "    # dataset\n",
        "    dataset = MyDataset(excel_file=config['file'], tokenizer=tokenizer, max_length=config['max_length'])\n",
        "\n",
        "    train_dataset, validation_dataset = train_test_split(dataset, test_size=0.2)\n",
        "\n",
        "    # trainloader\n",
        "    train_loader = dataloader(train_dataset, batch_size=config['batch_size'], shuffle=True)\n",
        "    validation_loader = dataloader(validation_dataset, batch_size=config['batch_size'], shuffle=False)\n",
        "\n",
        "    # model\n",
        "    model = CustomModel(model_name=config['model_name'], num_classes=config['num_classes'])\n",
        "    model.to(config['device'])\n",
        "\n",
        "    loss_fn = nn.CrossEntropyLoss()\n",
        "    optimizer = AdamW(model.parameters(), lr=config['learning_rate'])\n",
        "\n",
        "    for epoch in range(config['num_epochs']):\n",
        "        loss_train = train_step(model, train_loader, optimizer, loss_fn, config['device'])\n",
        "        loss_validatiton, accuracy = validation_step(model, validation_loader, loss_fn, config['device'])\n",
        "\n",
        "        wandb.log({\n",
        "            \"loss_train\":loss_train,\n",
        "            \"loss_validatiton\":loss_validatiton,\n",
        "            \"accuracy\":accuracy\n",
        "            })\n",
        "\n",
        "    return {\n",
        "        \"tokenizer\":tokenizer,\n",
        "        \"model\":model\n",
        "    }"
      ],
      "metadata": {
        "id": "he5vo6uQeRCh"
      },
      "execution_count": 113,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "my_model = main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 465
        },
        "id": "owcgx2CYeWWX",
        "outputId": "12bf25fa-d70d-4f0c-deee-820fcef39902"
      },
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Finishing last run (ID:65oqkpqk) before initializing another..."
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>▁</td></tr><tr><td>loss_train</td><td>▁</td></tr><tr><td>loss_validatiton</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>3194.73682</td></tr><tr><td>loss_train</td><td>0.72544</td></tr><tr><td>loss_validatiton</td><td>0.61484</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">still-serenity-16</strong> at: <a href='https://wandb.ai/utech/uncategorized/runs/65oqkpqk' target=\"_blank\">https://wandb.ai/utech/uncategorized/runs/65oqkpqk</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20230907_151411-65oqkpqk/logs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Successfully finished last run (ID:65oqkpqk). Initializing new run:<br/>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.15.10"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20230907_152304-kwljewo7</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/utech/uncategorized/runs/kwljewo7' target=\"_blank\">astral-wildflower-17</a></strong> to <a href='https://wandb.ai/utech/uncategorized' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/utech/uncategorized' target=\"_blank\">https://wandb.ai/utech/uncategorized</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/utech/uncategorized/runs/kwljewo7' target=\"_blank\">https://wandb.ai/utech/uncategorized/runs/kwljewo7</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n",
            "100%|██████████| 606/606 [00:50<00:00, 12.03it/s]\n",
            "100%|██████████| 152/152 [00:03<00:00, 43.03it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#sauvegarde du model et du tokenizer\n",
        "my_model['model'].save_pretrained(\"my_bert_model\")\n",
        "\n",
        "my_model['tokenizer'].save_pretrained(\"my_bert_model\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6kzpkXAgPsc-",
        "outputId": "c23a742a-8e1c-48e9-facc-472c565c8566"
      },
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('my_bert_model/tokenizer_config.json',\n",
              " 'my_bert_model/special_tokens_map.json',\n",
              " 'my_bert_model/vocab.txt',\n",
              " 'my_bert_model/added_tokens.json',\n",
              " 'my_bert_model/tokenizer.json')"
            ]
          },
          "metadata": {},
          "execution_count": 110
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# my_model['tokenizer'].push_to_hub(\"my_bert_model\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wWbsJj-GQXr_",
        "outputId": "42fe0f3d-7f82-4368-d0bc-7e2f30eeaaef"
      },
      "execution_count": 112,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CommitInfo(commit_url='https://huggingface.co/billfass/my_bert_model/commit/44db32839e3842b868702aa6d3bda473f40c2cff', commit_message='Upload tokenizer', commit_description='', oid='44db32839e3842b868702aa6d3bda473f40c2cff', pr_url=None, pr_revision=None, pr_num=None)"
            ]
          },
          "metadata": {},
          "execution_count": 112
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Deployment"
      ],
      "metadata": {
        "id": "eNATyPyvvWfv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git config --global credential.helper store\n",
        "!huggingface-cli login"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "slLPIqQGG3qQ",
        "outputId": "b09386ec-2f2c-4f0d-a80e-0ab0d5b5453f"
      },
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "    _|    _|  _|    _|    _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|_|_|_|    _|_|      _|_|_|  _|_|_|_|\n",
            "    _|    _|  _|    _|  _|        _|          _|    _|_|    _|  _|            _|        _|    _|  _|        _|\n",
            "    _|_|_|_|  _|    _|  _|  _|_|  _|  _|_|    _|    _|  _|  _|  _|  _|_|      _|_|_|    _|_|_|_|  _|        _|_|_|\n",
            "    _|    _|  _|    _|  _|    _|  _|    _|    _|    _|    _|_|  _|    _|      _|        _|    _|  _|        _|\n",
            "    _|    _|    _|_|      _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|        _|    _|    _|_|_|  _|_|_|_|\n",
            "    \n",
            "    A token is already saved on your machine. Run `huggingface-cli whoami` to get more information or `huggingface-cli logout` if you want to log out.\n",
            "    Setting a new token will erase the existing one.\n",
            "    To login, `huggingface_hub` requires a token generated from https://huggingface.co/settings/tokens .\n",
            "Token: \n",
            "Add token as git credential? (Y/n) Y\n",
            "Token is valid (permission: write).\n",
            "Your token has been saved in your configured git credential helpers (store).\n",
            "Your token has been saved to /root/.cache/huggingface/token\n",
            "Login successful\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Créer un nouveau dépôt sur Hugging Face\n",
        "!huggingface-cli repo create my_bert_model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EUGiLw0zPcQD",
        "outputId": "47314707-8c3c-49cb-da71-1a8116ec124b"
      },
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[90mgit version 2.34.1\u001b[0m\n",
            "\u001b[90mgit-lfs/3.0.2 (GitHub; linux amd64; go 1.18.1)\u001b[0m\n",
            "\n",
            "You are about to create \u001b[1mbillfass/my_bert_model\u001b[0m\n",
            "Proceed? [Y/n] Y\n",
            "\n",
            "Your repo now lives at:\n",
            "  \u001b[1mhttps://huggingface.co/billfass/my_bert_model\u001b[0m\n",
            "\n",
            "You can clone it locally with the command below, and commit/push as usual.\n",
            "\n",
            "  git clone https://huggingface.co/billfass/my_bert_model\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/\n",
        "!git clone  https://huggingface.co/billfass/my_bert_model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EoSqnSgMGpKa",
        "outputId": "6bafa7fa-3775-4270-ba50-927df59099a0"
      },
      "execution_count": 120,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "Cloning into 'my_bert_model'...\n",
            "remote: Enumerating objects: 12, done.\u001b[K\n",
            "remote: Counting objects: 100% (9/9), done.\u001b[K\n",
            "remote: Compressing objects: 100% (9/9), done.\u001b[K\n",
            "remote: Total 12 (delta 1), reused 0 (delta 0), pack-reused 3\u001b[K\n",
            "Unpacking objects: 100% (12/12), 1.43 MiB | 4.90 MiB/s, done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git config --global user.email \"billfass2010@mail.com\"\n",
        "!git config --global user.name \"billfass\""
      ],
      "metadata": {
        "id": "OKHAoc6jI9pr"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Pousser le modèle et le tokenizer sur le hub Hugging Face\n",
        "%cd /content/my_bert_model\n",
        "\n",
        "!git add .\n",
        "!git commit -m \"Initial commit of BertModel and tokenizer\"\n",
        "!git push\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "tKWbm1OSRVqo",
        "outputId": "6c927fe3-98d1-4218-9578-e840b0267bcc"
      },
      "execution_count": 124,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/my_bert_model\n",
            "[main e55d58e] Initial commit of BertModel and tokenizer\n",
            " 1 file changed, 10 insertions(+), 9 deletions(-)\n",
            "Enumerating objects: 5, done.\n",
            "Counting objects: 100% (5/5), done.\n",
            "Delta compression using up to 8 threads\n",
            "Compressing objects: 100% (3/3), done.\n",
            "Writing objects: 100% (3/3), 452 bytes | 452.00 KiB/s, done.\n",
            "Total 3 (delta 2), reused 0 (delta 0), pack-reused 0\n",
            "To https://huggingface.co/billfass/my_bert_model\n",
            "   22bd428..e55d58e  main -> main\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "V100"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}